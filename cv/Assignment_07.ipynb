{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b071bc",
   "metadata": {},
   "source": [
    "# Assignment 07 Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417156ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faed445a",
   "metadata": {},
   "source": [
    "#### 1. What is the COVARIATE SHIFT Issue, and how does it affect you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52548cb",
   "metadata": {},
   "source": [
    "    We have a Two Major Assumptions in Supervised learning, that are \n",
    "        1. IID data (Independet and Indentical Distribution).\n",
    "        2. There should be relationship between i.v and d.v\n",
    "        \n",
    "    So, when a model is trained using a dataset, the dataset maximum won't be a population dataset, it will be sample from the popultion. So, if the model is trained on one set of samples, and inference on another set of samples which is from same dataset, but has a different input distribution, then our model won't work well. Because of property of iid.\n",
    "    \n",
    "    So, when a model is trained on different distribution and inference on different distribution from the training distribution, then it is known as a Convariance-shift(Distributional drift).\n",
    "    \n",
    "    Covariate shift is a change in the distribution of the model’s inputs between training and production data.\n",
    "    \n",
    "    eg:\n",
    "        You are building a model for face recoginition, where you have a model build with the faces from american people, and inference on the asian people, where the model is trained on different distribution and tested on different distribution. American people distribution will differ from asian people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5835ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58e99aa7",
   "metadata": {},
   "source": [
    "#### 2. What is the process of BATCH NORMALIZATION?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7997d5",
   "metadata": {},
   "source": [
    "    Batch normalization (also known as batch norm) is a method used to make training of artificial neural networks faster and more stable through normalization of the layers'\n",
    "    \n",
    "    While the effect of batch normalization is evident, the reasons behind its effectiveness remain under discussion. It was believed that it can mitigate the problem of internal covariate shift, where parameter initialization and changes in the distribution of the inputs of each layer affect the learning rate of the network. Recently, some scholars have argued that batch normalization does not reduce internal covariate shift, but rather smooths the objective function, which in turn improves the performance However, at initialization, batch normalization in fact induces severe gradient explosion in deep networks, which is only alleviated by skip connections in residual networks.[3] Others maintain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks.[4] More recently a normalize gradient clipping technique and smart hyperparameter tuning has been introduced in Normalizer-Free Nets, so called \"NF-Nets\" which mitigates the need for batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0cf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c2e3dd0",
   "metadata": {},
   "source": [
    "#### 3. Using our own terms and diagrams, explain LENET ARCHITECTURE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ba739",
   "metadata": {},
   "source": [
    "    LeNet-5 is one of the first convolution pretraining model to be introduced. It is intially used for detecting the signature in bank cheque, used for the image classification tasks.\n",
    "    \n",
    "    Model Architecture:\n",
    "        Lenet-5, has a simple model architecure with only 5 layers, that is what the 5 in lenet-5 means. t has three sets of convolution layers with a combination of average pooling. After the convolution and average pooling layers, we have two fully connected layers. At last, a Softmax classifier which classifies the images into respective class. It uses the sigmoid activation function.\n",
    "        \n",
    "        Each layer convolution has a kernel size of (5, 5), and relu activation function, but with increasing of the channels(filters).\n",
    "        \n",
    "        It takes the GrayScale image as an input. eg: (28, 28, 1)\n",
    "        \n",
    "   <img src='https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-18-12-22-52.png' />\n",
    "   \n",
    "       First module:\n",
    "           1. We will use the kerne size of 5 * 5, and 6 filters, so the result will be (28, 28, 6), will be the output of first convolutional operation. calculation = 28 - 5 + 2(2) / 1 + 1\n",
    "           \n",
    "           2. Now, sigmoid activation function will be applied.\n",
    "           \n",
    "           3. Average Pooling layer, with kernel size of (2, 2) and strides of 2. So the output will be (14, 14, 6). Calculation = 28 - 2 / 2 + 1.\n",
    "           \n",
    "      Second Module;\n",
    "          1. It uses the kernel size of (5, 5) with 16 filters with 0 padding. so the result will be (10, 10, 16). calculation = 14 - 5 / 1 + 1.\n",
    "          \n",
    "          2. Now, sigmoid activation function will be applied.\n",
    "          \n",
    "          3. Average Pooling layer, with kernel size of (2, 2) and strides of 2. So the output will be (5, 5, 16). Calculation = 10 - 2 / 2 + 1.\n",
    "          \n",
    "      Flatten layer will be applied to (5, 5, 16) input, output dimension will be 400.\n",
    "      \n",
    "      Two fully connected layer with 120 neurons, and 84 neurons will applied sequentially. And final layer will be of 10 dimension for MNIST dataset with sofmax activation function.\n",
    "      \n",
    "   <img src='https://d2l.ai/_images/lenet-vert.svg' />\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8c2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a48450ca",
   "metadata": {},
   "source": [
    "#### 4. Using our own terms and diagrams, explain ALEXNET ARCHITECTURE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307d017",
   "metadata": {},
   "source": [
    "    AlexNet, which employed an 8-layer CNN, won the ImageNet Large Scale Visual Recognition Challenge 2012 by a large margin (Russakovsky et al., 2013).This network showed, for the first time, that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision.\n",
    "    \n",
    "    The architectures of AlexNet and LeNet are strikingly similar, as Fig. 8.1.2 illustrates. Note that we provide a slightly streamlined version of AlexNet removing some of the design quirks that were needed in 2012 to make the model fit on two small GPUs.\n",
    "    \n",
    "      Comparsion between alexnet and lenet\n",
    "   <img src='https://d2l.ai/_images/alexnet.svg' />\n",
    "     \n",
    "     There are also significant differences between AlexNet and LeNet. First, AlexNet is much deeper than the comparatively small LeNet5. AlexNet consists of eight layers: five convolutional layers, two fully connected hidden layers, and one fully connected output layer. Second, AlexNet used the ReLU instead of the sigmoid as its activation function. Let’s delve into the details below.\n",
    "     \n",
    "     In AlexNet’s first layer, the convolution window shape is (11, 11). Since the images in ImageNet are eight times higher and wider than the MNIST images, objects in ImageNet data tend to occupy more pixels with more visual detail. Consequently, a larger convolution window is needed to capture the object. The convolution window shape in the second layer is reduced to (5, 5), followed by (3, 3). In addition, after the first, second, and fifth convolutional layers, the network adds max-pooling layers with a window shape of  and a stride of 2. Moreover, AlexNet has ten times more convolution channels than LeNet.\n",
    "\n",
    "    After the last convolutional layer, there are two huge fully connected layers with 4096 outputs. These layers require nearly 1GB model parameters. Due to the limited memory in early GPUs, the original AlexNet used a dual data stream design, so that each of their two GPUs could be responsible for storing and computing only its half of the model. Fortunately, GPU memory is comparatively abundant now, so we rarely need to break up models across GPUs these days (our version of the AlexNet model deviates from the original paper in this aspect).\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90aecec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7739ebe2",
   "metadata": {},
   "source": [
    "#### 5. Describe the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4b90f",
   "metadata": {},
   "source": [
    "    The vanishing gradient problem is a problem that you face when you are training Neural Networks by using gradient-based methods like backpropagation. This problem makes it difficult to learn and tune the parameters of the earlier layers in the network. \n",
    "    \n",
    "    he vanishing gradient problem is essentially a situation in which a deep multilayer feed-forward network or a recurrent neural network (RNN) does not have the ability to propagate useful gradient information from the output end of the model back to the layers near the input end of the model.\n",
    "\n",
    "    It results in models with many layers being rendered unable to learn on a specific dataset. It could even cause models with many layers to prematurely converge to a substandard solution.\n",
    "\n",
    "    When the backpropagation algorithm advances downwards(or backward) going from the output layer to the input layer, the gradients tend to shrink, becoming smaller and smaller till they approach zero. This ends up leaving the weights of the initial or lower layers practically unchanged. In this situation, the gradient descent does not ever end up converging to the optimum. \n",
    "    \n",
    "    Vanishing gradient does not necessarily imply that the gradient vector is all zero (with the exception of numerical overflow). It implies that the gradients are minuscule, which would cause the learning to be very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1e05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5884885",
   "metadata": {},
   "source": [
    "#### 6. What is NORMALIZATION OF LOCAL RESPONSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0f96c",
   "metadata": {},
   "source": [
    "    Local Response Normalization (LRN) was first introduced in AlexNet architecture where the activation function used was ReLU as opposed to the more common tanh and sigmoid at that time. Apart from the reason mentioned above, the reason for using LRN was to encourage lateral inhibition. It is a concept in Neurobiology that refers to the capacity of a neuron to reduce the activity of its neighbors [1]. In DNNs, the purpose of this lateral inhibition is to carry out local contrast enhancement so that locally maximum pixel values are used as excitation for the next layers.\n",
    "    \n",
    "    LRN is a non-trainable layer that square-normalizes the pixel values in a feature map within a local neighborhood.\n",
    "    \n",
    "  <img src='https://miro.medium.com/v2/resize:fit:786/format:webp/1*DmnOhSTIzn04sC0w1d3FPg.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb4cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32f4b2a4",
   "metadata": {},
   "source": [
    "#### 7. In AlexNet, what WEIGHT REGULARIZATION was used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2564045",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a499f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40ea60fd",
   "metadata": {},
   "source": [
    "#### 8. Using our own terms and diagrams, explain VGGNET ARCHITECTURE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a574176",
   "metadata": {},
   "source": [
    "    Like AlexNet and LeNet, the VGG Network can be partitioned into two parts: the first consisting mostly of convolutional and pooling layers and the second consisting of fully connected layers that are identical to those in AlexNet. The key difference is that the convolutional layers are grouped in nonlinear transformations that leave the dimensonality unchanged, followed by a resolution-reduction step,\n",
    "    \n",
    "    The convolutional part of the network connects several VGG blocks(also defined in the vgg_block function) in succession. This grouping of convolutions is a pattern that has remained almost unchanged over the past decade, although the specific choice of operations has undergone considerable modifications. The variable conv_arch consists of a list of tuples (one per block), where each contains two values: the number of convolutional layers and the number of output channels, which are precisely the arguments required to call the vgg_block function. As such, VGG defines a family of networks rather than just a specific manifestation. To build a specific network we simply iterate over arch to compose the blocks.\n",
    "    \n",
    "    The original VGG network had 5 convolutional blocks, among which the first two have one convolutional layer each and the latter three contain two convolutional layers each. The first block has 64 output channels and each subsequent block doubles the number of output channels, until that number reaches 512.\n",
    "    \n",
    "  <img src='https://d2l.ai/_images/vgg.svg' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1260b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0240feaa",
   "metadata": {},
   "source": [
    "#### 9. Describe VGGNET CONFIGURATIONS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1910133",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7de9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b526e6",
   "metadata": {},
   "source": [
    "#### 10. What regularization methods are used in VGGNET to prevent overfitting? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4da26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b7673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a300559d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246d2fe",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8aa18",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4effd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac40b1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e94190",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84baff66",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff43a28",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
