{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b071bc",
   "metadata": {},
   "source": [
    "# Assignment 06 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed445a",
   "metadata": {},
   "source": [
    "#### 1. What is the difference between TRAINABLE and NON-TRAINABLE PARAMETERS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a1338",
   "metadata": {},
   "source": [
    "    When the neural network is build, we gonna have a deep neural network, where depth refer to the number of layers in the network. So width refer to the channels and spatial dimension, so when we have deep neural network, once it is build, it gonna have two types of parameters trainable and non-trainable. Trainable parameter means, whenever the model is trained, our optimizer, will update the weights and bias of that layer, if the layer is non-trainable, then whenever the model is trained, that layers, weight and biases are not updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735adaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0804ecc1",
   "metadata": {},
   "source": [
    "#### 2. In the CNN architecture, where does the DROPOUT LAYER go?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddbae28",
   "metadata": {},
   "source": [
    "    Dropout layer is one type of regualization technique in the neural network, Which is used to solve the problems of overfitting of neural network. When we use the dropout, we are making sure that neurons in the current layers not depended on specific neurons in previous layers. We use dropout layer between two layer like (between two dense layers or conv layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4553925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a300559d",
   "metadata": {},
   "source": [
    "#### 3. What is the optimal number of hidden layers to stack?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c10bff0",
   "metadata": {},
   "source": [
    "     There's one additional rule of thumb that helps for supervised learning problems. You can usually prevent over-fitting if you keep your number of neurons below:\n",
    "\n",
    "    Nh=Ns(α∗(Ni+No))\n",
    "\n",
    "    Ni = number of input neurons.\n",
    "    No = number of output neurons.\n",
    "    Ns = number of samples in training data set.\n",
    "    α = an arbitrary scaling factor usually 2-10.\n",
    "\n",
    "    Others recommend setting α to a value between 5 and 10, but I find a value of 2 will often work without overfitting. You can think of α as the effective branching factor or number of nonzero weights for each neuron. Dropout layers will bring the \"effective\" branching factor way down from the actual mean branching factor for your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66507fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4246d2fe",
   "metadata": {},
   "source": [
    "#### 4. In each layer, how many secret units or filters should there be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bed136",
   "metadata": {},
   "source": [
    "    1 Avoid Representational Bottlenecks, Especially Early in the Network\n",
    "\n",
    "    The representation (feature map) size should gently decrease from the inputs to the outputs before reaching the final representation used for the task at hand. The dimensionality merely provides a rough estimate of information content since it discards important factors like correlation structure.\n",
    "\n",
    "    2 Higher Dimensional Representations are Easier to Process Locally Within a Network\n",
    "\n",
    "    Increasing the activations per tile in a convolutional network allows for more isentangled features. The resulting networks will train faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f513fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76b8aa18",
   "metadata": {},
   "source": [
    "#### 5. What should your initial learning rate be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb0a9f2",
   "metadata": {},
   "source": [
    "    The range of values to consider for the learning rate is less than 1.0 and greater than 10^-6. A traditional default value for the learning rate is 0.1 or 0.01, and this may represent a good starting point on your problem. The grid search approach can help to both highlight an order of magnitude where good learning rates may reside, as well as describe the relationship between learning rate and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d000480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bf4effd",
   "metadata": {},
   "source": [
    "#### 6. What do you do with the activation function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de784677",
   "metadata": {},
   "source": [
    "    An Activation Function decides whether a neuron should be activated or not. This means that it will decide whether the neuron's input to the network is important or not in the process of prediction using simpler mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27468c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fac40b1",
   "metadata": {},
   "source": [
    "#### 7. What is NORMALIZATION OF DATA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b85c255",
   "metadata": {},
   "source": [
    "    Normalization is a way of making the input distribution of data into defined distribution like 0-1, or -1 to 1. Which makes our neural network to converge quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205aa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36e94190",
   "metadata": {},
   "source": [
    "#### 8. What is IMAGE AUGMENTATION and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7e2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d028d47",
   "metadata": {},
   "source": [
    "    Data Augmentation is type of regularization technique, which is used to solve the problem of overfitting, the model tends to overfit to specific group of data, and also if it does'nt have a diversion/ enough variation to represent the dataset. And also in many tasks, there won't be enough umber of samples in dataset, one way to generate the samples is using data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84baff66",
   "metadata": {},
   "source": [
    "#### 9. What is DECLINE IN LEARNING RATE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb1af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dff43a28",
   "metadata": {},
   "source": [
    "#### 10. What does EARLY STOPPING CRITERIA mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24dcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
